{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5주차 과제\n",
    "\n",
    "Made by 35기 코딩부장 류제현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝의 처음부터 끝까지\n",
    "\n",
    "Mnist 데이터셋을 가지고 숫자 손글씨를 인식하는 분류기를 만들어 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우선 데이터를 불러오겠습니다\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "\n",
    "# X,y를 분리해 줍니다\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터는 이렇게 생겼습니다\n",
    "print(X.shape) # (28*28)크기의 이미지 입니다\n",
    "print(y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    문제1) Train_test_split을 사용해 X,y를 Train_set과 Test_set으로 나눠주세요!\n",
    "\n",
    "* 주의! 결과를 동일하게 맞추기 위해서 train_test_split(random_state=10)으로 지정해 주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 1 코드\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    문제2) Standard Scaler를 사용해서 데이터를 표준화 해봅시다\n",
    "\n",
    "* 주의1) Test 데이터는 fit 시키지 말고, Train 데이터에서 fit 시킨 것을 가지고 transform만 해줘야 합니다!\n",
    "\n",
    "* 주의2) 정답지(y)는 수정하면 안되겠죠? 그대로 남겨 둬야 합니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 2 코드\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    문제3) RandomForestClassifier의 기본(Default) 파라미터 값으로 모델을 훈련시켜 봅시다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제 3 코드\n",
    "# SVC는 Support Vector Classifier를 의미합니다\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    문제4) 위에서 학습시킨 분류기의 정확도(Accuracy), 정밀도(Precision score), 재현율(Recall Score)를 구해봅시다  \n",
    "\n",
    "* 주의 1) Train 데이터에 대한 점수, Test 데이터에 대한 점수를 모두 구해봅시다!\n",
    "\n",
    "* 주의 2) precision_score와 recall_score를 구할때 average=\"macro\"로 지정해줘야 합니다! 이에 대한 설명은 수업시간에 하도록 하겠습니다\n",
    "\n",
    "* 주의 3) StandardScaler를 사용해 표준화한 Train 데이터를 사용했기 때문에, 점수를 구할 때도 표준화 시킨 Train 데이터를 사용해야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  1.0\n",
      "정밀도:  1.0\n",
      "재현율:  1.0\n"
     ]
    }
   ],
   "source": [
    "# 문제 4-1) Train_data에 대한 점수\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(\"정확도: \", model.score(X_train_scaled, \n",
    "                             y_train))\n",
    "\n",
    "print(\"정밀도: \", precision_score(y_train, \n",
    "                                 model.predict(X_train_scaled), \n",
    "                                 average=\"macro\"))\n",
    "\n",
    "print(\"재현율: \", recall_score(y_train,\n",
    "                              model.predict(X_train_scaled),\n",
    "                              average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.9666285714285714\n",
      "정밀도:  0.9664111262485772\n",
      "재현율:  0.9665316382915259\n"
     ]
    }
   ],
   "source": [
    "# 문제 4-2) Test-Data에 대한 점수\n",
    "\n",
    "print(\"정확도: \", model.score(X_test_scaled, \n",
    "                             y_test))\n",
    "\n",
    "print(\"정밀도: \", precision_score(y_test, \n",
    "                                 model.predict(X_test_scaled), \n",
    "                                 average=\"macro\"))\n",
    "\n",
    "print(\"재현율: \", recall_score(y_test,\n",
    "                              model.predict(X_test_scaled),\n",
    "                              average=\"macro\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    문제 5) Grid-Search를 사용해서 RandomForest 모델의 최적의 파라미터를 찾아 봅시다\n",
    "\n",
    "* 주의) GridSearchCV의 파라미터를 cv=4, n_jobs=-1로 지정해주세요\n",
    "\n",
    "* Train 데이터는 위에서와 똑같은 Scaled된 데이터를 사용해주세요\n",
    "\n",
    "* 학습 속도를 위해서는 데이터의 일부만 가지고 Grid-Search를 하는 것이 현명합니다! 데이터 10000개만 가지고 Grid-search를 해봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30, 'n_estimators': 1000}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제 5-1) 10000개의 데이터만 가지고 GridSearch를 수행하고, 최적의 파라미터를 찾아봅시다\n",
    "## 데이터 10000개 예시 코드 -> X_train[:10000]\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_params = {\"n_estimators\": [100, 500, 1000],\n",
    "               \"max_depth\": [10,30,50,70]}\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "grid_clf = GridSearchCV(forest, param_grid=grid_params,\n",
    "                        cv=4, n_jobs=-1)\n",
    "\n",
    "grid_clf.fit(X_train_scaled[:10000], y_train[:10000])\n",
    "grid_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=30, n_estimators=1000, n_jobs=-1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제 5-2) 앞에서 찾은 최적의 파라미터로, Train 데이터를 전부 사용해 모델을 훈련시켜봅시다\n",
    "\n",
    "forest_best = RandomForestClassifier(n_estimators=1000, \n",
    "                                     max_depth=30,\n",
    "                                     n_jobs=-1) # n_jobs: 속도 향상을 위해\n",
    "forest_best.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    문제6) 위에서 학습시킨 분류기의 정확도(Accuracy), 정밀도(Precision score), 재현율(Recall Score)를 구해봅시다  \n",
    "\n",
    "* 주의 1) Test 데이터에 대한 점수만 구해봅시다!\n",
    "\n",
    "* 주의 2) precision_score함수와 recall_score 함수에 average=\"macro\"로 지정해줘야 합니다!\n",
    "\n",
    "* 주의 3) StandardScaler를 사용해 표준화한 Train 데이터를 사용했기 때문에, 점수를 구할 때도 표준화한 Test 데이터를 사용해야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.9684571428571429\n",
      "정밀도:  0.9682957037763151\n",
      "재현율:  0.9683248885491318\n"
     ]
    }
   ],
   "source": [
    "# 문제 6 코드) Test 데이터에 대한 모델의 정확도, 정밀도, 재현율을 구해봅시다\n",
    "print(\"정확도: \", forest_best.score(X_test_scaled, \n",
    "                             y_test))\n",
    "\n",
    "print(\"정밀도: \", precision_score(y_test, \n",
    "                                 forest_best.predict(X_test_scaled), \n",
    "                                 average=\"macro\"))\n",
    "\n",
    "print(\"재현율: \", recall_score(y_test,\n",
    "                              forest_best.predict(X_test_scaled),\n",
    "                              average=\"macro\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고생하셨습니다!! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
